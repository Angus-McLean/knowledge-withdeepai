{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse .env yaml file\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(\".env.yaml\", 'r') as stream:\n",
    "    ## add to env variables OPENAI_API_KEY\n",
    "    obj = yaml.safe_load(stream)\n",
    "    os.environ[\"OPENAI_API_KEY\"] = obj[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from langchain import LLMChain\n",
    "\n",
    "\n",
    "class AtlasBuilder():\n",
    "\n",
    "    template = '''\n",
    "Please help me create a hierarchical taxonomy for the Atlas of Knowledge, an organized and very comprehensive map of all topics/categories/areas/techniques within \"{topic}\". \n",
    "\n",
    "Start with the broad topics, then break them down into subtopics where applicable. Only include the topic taxonomy and nothing else.\n",
    "\n",
    "---- Sample Output ----\n",
    "1. Topic1\n",
    "1.1. SubTopic1\n",
    "    1.1.1. SubSubTopic1\n",
    "    1.1.2. SubSubTopic2\n",
    "1.2. SubTopic2\n",
    "    1.2.1. SubSubTopic1\n",
    "2. Topic2\n",
    "2.1. SubTopic1\n",
    "    2.1.1. SubSubTopic1\n",
    "    2.1.2. SubSubTopic2\n",
    "    2.1.3. SubSubTopic3\n",
    "    2.1.4. SubSubTopic4\n",
    "    2.1.5. SubSubTopic5\n",
    "    2.1.6. SubSubTopic6\n",
    "    2.1.7. SubSubTopic7\n",
    "    2.1.8. SubSubTopic8\n",
    "2.2. SubTopic2\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "'''\n",
    "\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\", root_folder_path='public/knowledge_atlas'):\n",
    "        self.root_folder_path = root_folder_path\n",
    "\n",
    "        self.llm = ChatOpenAI(model_name=model_name, temperature=0.0, max_tokens=3000, top_p=1, frequency_penalty=0.0, presence_penalty=0.0)\n",
    "        prompt_template = PromptTemplate(input_variables=[\"topic\"], template=self.template)\n",
    "        self.answer_chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
    "        \n",
    "    def query_openai(self, topic_path):\n",
    "        answer = self.answer_chain.run(topic=topic_path)\n",
    "        return answer\n",
    "    \n",
    "    def get_topic_hierarchy(self, topic_path):\n",
    "        answer = self.query_openai(topic_path)\n",
    "        return self.parse_hierarchical_list(answer, start_path=topic_path)\n",
    "\n",
    "    def write_topic_hierarchy(self, topic_json):\n",
    "        leaf_folder_path = os.path.join(self.root_folder_path, *topic_json['path'].split(' > '), topic_json['name'])\n",
    "        self.add_json_to_folder_structure(topic_json, leaf_folder_path)\n",
    "\n",
    "    def get_leaf_paths(self):\n",
    "        lowest_dirs = []\n",
    "        for root,dirs,files in os.walk(self.root_folder_path):\n",
    "            if not dirs:lowest_dirs.append(root)\n",
    "        lowest_dirs.sort(key=lambda x: x.count('/'))\n",
    "        return lowest_dirs\n",
    "\n",
    "# WRITING TO FILES\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_hierarchical_list(text, start_path=''):\n",
    "        lines = text.strip().split('\\n')\n",
    "        stack = []\n",
    "        start_name = start_path.split(' > ')[-1]\n",
    "        root = {\n",
    "            'name': start_name, \n",
    "            'children': {}, \n",
    "            'path': ' > '.join(start_path.split(' > ')[:-1])\n",
    "        }\n",
    "        stack.append(root)\n",
    "\n",
    "        for line in lines:\n",
    "            if not line : continue      # Note : this stops parsing at any empty lines... Not sure why, hence this fix\n",
    "\n",
    "            level = len(re.findall(r'\\d\\.', line))\n",
    "            name = re.sub(r'\\d+\\.', '', line).strip()\n",
    "            node = {'name': name, 'children': {}}\n",
    "\n",
    "            while len(stack) > level:\n",
    "                stack.pop()\n",
    "\n",
    "            if level > 0:\n",
    "                node['path'] = stack[-1]['path'] + ' > ' + stack[-1]['name']\n",
    "                node['path'] = re.sub( r'^ > ', '', node['path'])\n",
    "                stack[-1]['children'][name] = node\n",
    "\n",
    "            stack.append(node)\n",
    "\n",
    "        return root\n",
    "\n",
    "    @staticmethod\n",
    "    def add_json_to_folder_structure(json_object, root_folder_path):\n",
    "        if not os.path.exists(root_folder_path):\n",
    "            os.mkdir(root_folder_path)\n",
    "\n",
    "        # If the JSON object has children, create subfolders for each child\n",
    "        if 'children' in json_object:\n",
    "            for child_name, child_obj in json_object['children'].items():\n",
    "                child_folder_path = os.path.join(root_folder_path, child_name)\n",
    "                AtlasBuilder.add_json_to_folder_structure(child_obj, child_folder_path)\n",
    "\n",
    "        # Write the JSON object to a file in the current folder\n",
    "        json_file_path = os.path.join(root_folder_path, 'data.json')\n",
    "        with open(json_file_path, 'w') as f:\n",
    "            json.dump(AtlasBuilder.trim_json(json_object, 4), f)\n",
    "\n",
    "    @staticmethod\n",
    "    def trim_json(json_object, max_level=3, current_level=0):\n",
    "        \"\"\"\n",
    "        Trims a JSON object to only X levels down.\n",
    "\n",
    "        Args:\n",
    "            json_object (dict): The JSON object to trim.\n",
    "            current_level (int): The current level of the JSON object.\n",
    "            max_level (int): The maximum level to include in the trimmed JSON object.\n",
    "\n",
    "        Returns:\n",
    "            dict: The trimmed JSON object.\n",
    "        \"\"\"\n",
    "        # Base case: if we've reached the maximum level, return an empty dictionary\n",
    "        if (current_level == max_level) or (not json_object):\n",
    "            return {}\n",
    "\n",
    "        # If the JSON object has children, recursively trim them and add them to a new dictionary\n",
    "        trimmed_object = {}\n",
    "        if 'children' in json_object:\n",
    "            for child_name, child_obj in json_object['children'].items():\n",
    "                trimmed_child = AtlasBuilder.trim_json(child_obj, current_level=current_level+1, max_level=max_level)\n",
    "                if trimmed_child:\n",
    "                    trimmed_object[child_name] = trimmed_child\n",
    "\n",
    "        # Include the current object's name and any non-children attributes in the trimmed object\n",
    "        # print(json_object)\n",
    "        trimmed_object['name'] = json_object['name']\n",
    "        for key, value in json_object.items():\n",
    "            if key != 'name' and key != 'children':\n",
    "                trimmed_object[key] = value\n",
    "\n",
    "        return trimmed_object\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Knowledge Atlas!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start With \"All Knowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_PATH = \"All Knowledge\"\n",
    "# TOPIC_PATH = \"Natural Sciences > Biology > Genetics\"\n",
    "\n",
    "atlas = AtlasBuilder(model_name='gpt-4')\n",
    "topic_hierarchy = atlas.get_topic_hierarchy(TOPIC_PATH)\n",
    "# topic_hierarchy\n",
    "\n",
    "# RUN WITH CAUTION -- OVERWRITES EXISTING FILES\n",
    "# atlas.write_topic_hierarchy(topic_hierarchy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Topics to Expand \n",
    "(Leaf Nodes - Breadth-first search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Horticulture',\n",
       " 'path': 'All Knowledge > Applied Sciences > Agriculture'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Leaf node, get the JSON\n",
    "\n",
    "# randomly select a leaf path\n",
    "import random\n",
    "leaf_path = random.choice(atlas.get_leaf_paths())\n",
    "leaf_topic_json = json.load(open(leaf_path+'/data.json'))\n",
    "leaf_topic_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Horticulture',\n",
       " 'children': {'Plant Science': {'name': 'Plant Science',\n",
       "   'children': {'Plant Anatomy': {'name': 'Plant Anatomy',\n",
       "     'children': {'Plant Cells': {'name': 'Plant Cells',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Anatomy'},\n",
       "      'Plant Tissues': {'name': 'Plant Tissues',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Anatomy'},\n",
       "      'Plant Organs': {'name': 'Plant Organs',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Anatomy'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science'},\n",
       "    'Plant Physiology': {'name': 'Plant Physiology',\n",
       "     'children': {'Photosynthesis': {'name': 'Photosynthesis',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Physiology'},\n",
       "      'Respiration': {'name': 'Respiration',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Physiology'},\n",
       "      'Transpiration': {'name': 'Transpiration',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Physiology'},\n",
       "      'Plant Hormones': {'name': 'Plant Hormones',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Physiology'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science'},\n",
       "    'Plant Genetics': {'name': 'Plant Genetics',\n",
       "     'children': {'Plant Breeding': {'name': 'Plant Breeding',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Genetics'},\n",
       "      'Genetic Engineering': {'name': 'Genetic Engineering',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Genetics'},\n",
       "      'Plant Genomics': {'name': 'Plant Genomics',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science > Plant Genetics'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Plant Science'}},\n",
       "   'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture'},\n",
       "  'Soil Science': {'name': 'Soil Science',\n",
       "   'children': {'Soil Composition': {'name': 'Soil Composition',\n",
       "     'children': {'Soil Minerals': {'name': 'Soil Minerals',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Composition'},\n",
       "      'Soil Organic Matter': {'name': 'Soil Organic Matter',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Composition'},\n",
       "      'Soil Water': {'name': 'Soil Water',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Composition'},\n",
       "      'Soil Air': {'name': 'Soil Air',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Composition'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science'},\n",
       "    'Soil Fertility': {'name': 'Soil Fertility',\n",
       "     'children': {'Nutrient Cycling': {'name': 'Nutrient Cycling',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Fertility'},\n",
       "      'Soil pH': {'name': 'Soil pH',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Fertility'},\n",
       "      'Fertilizers': {'name': 'Fertilizers',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Fertility'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science'},\n",
       "    'Soil Management': {'name': 'Soil Management',\n",
       "     'children': {'Soil Conservation': {'name': 'Soil Conservation',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Management'},\n",
       "      'Soil Erosion Control': {'name': 'Soil Erosion Control',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Management'},\n",
       "      'Soil Amendments': {'name': 'Soil Amendments',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science > Soil Management'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Soil Science'}},\n",
       "   'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture'},\n",
       "  'Crop Production': {'name': 'Crop Production',\n",
       "   'children': {'Crop Cultivation': {'name': 'Crop Cultivation',\n",
       "     'children': {'Planting Techniques': {'name': 'Planting Techniques',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Cultivation'},\n",
       "      'Irrigation': {'name': 'Irrigation',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Cultivation'},\n",
       "      'Weed Control': {'name': 'Weed Control',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Cultivation'},\n",
       "      'Pest Management': {'name': 'Pest Management',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Cultivation'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production'},\n",
       "    'Crop Harvesting': {'name': 'Crop Harvesting',\n",
       "     'children': {'Harvesting Techniques': {'name': 'Harvesting Techniques',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Harvesting'},\n",
       "      'Post-Harvest Handling': {'name': 'Post-Harvest Handling',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Harvesting'},\n",
       "      'Storage': {'name': 'Storage',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Harvesting'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production'},\n",
       "    'Crop Types': {'name': 'Crop Types',\n",
       "     'children': {'Fruits': {'name': 'Fruits',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Types'},\n",
       "      'Vegetables': {'name': 'Vegetables',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Types'},\n",
       "      'Ornamental Plants': {'name': 'Ornamental Plants',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Types'},\n",
       "      'Medicinal Plants': {'name': 'Medicinal Plants',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production > Crop Types'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Crop Production'}},\n",
       "   'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture'},\n",
       "  'Landscape Design': {'name': 'Landscape Design',\n",
       "   'children': {'Garden Styles': {'name': 'Garden Styles',\n",
       "     'children': {'Formal Gardens': {'name': 'Formal Gardens',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Styles'},\n",
       "      'Informal Gardens': {'name': 'Informal Gardens',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Styles'},\n",
       "      'Japanese Gardens': {'name': 'Japanese Gardens',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Styles'},\n",
       "      'English Gardens': {'name': 'English Gardens',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Styles'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design'},\n",
       "    'Garden Elements': {'name': 'Garden Elements',\n",
       "     'children': {'Hardscape': {'name': 'Hardscape',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Elements'},\n",
       "      'Softscape': {'name': 'Softscape',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Elements'},\n",
       "      'Water Features': {'name': 'Water Features',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Elements'},\n",
       "      'Lighting': {'name': 'Lighting',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Elements'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design'},\n",
       "    'Garden Maintenance': {'name': 'Garden Maintenance',\n",
       "     'children': {'Pruning': {'name': 'Pruning',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Maintenance'},\n",
       "      'Mulching': {'name': 'Mulching',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Maintenance'},\n",
       "      'Fertilizing': {'name': 'Fertilizing',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Maintenance'},\n",
       "      'Pest Control': {'name': 'Pest Control',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design > Garden Maintenance'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Landscape Design'}},\n",
       "   'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture'},\n",
       "  'Horticultural Technology': {'name': 'Horticultural Technology',\n",
       "   'children': {'Greenhouse Technology': {'name': 'Greenhouse Technology',\n",
       "     'children': {'Greenhouse Structures': {'name': 'Greenhouse Structures',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Greenhouse Technology'},\n",
       "      'Environmental Control': {'name': 'Environmental Control',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Greenhouse Technology'},\n",
       "      'Hydroponics': {'name': 'Hydroponics',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Greenhouse Technology'},\n",
       "      'Integrated Pest Management': {'name': 'Integrated Pest Management',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Greenhouse Technology'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology'},\n",
       "    'Plant Propagation': {'name': 'Plant Propagation',\n",
       "     'children': {'Seed Propagation': {'name': 'Seed Propagation',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Plant Propagation'},\n",
       "      'Vegetative Propagation': {'name': 'Vegetative Propagation',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Plant Propagation'},\n",
       "      'Tissue Culture': {'name': 'Tissue Culture',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Plant Propagation'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology'},\n",
       "    'Horticultural Tools and Equipment': {'name': 'Horticultural Tools and Equipment',\n",
       "     'children': {'Hand Tools': {'name': 'Hand Tools',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Horticultural Tools and Equipment'},\n",
       "      'Power Tools': {'name': 'Power Tools',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Horticultural Tools and Equipment'},\n",
       "      'Irrigation Systems': {'name': 'Irrigation Systems',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Horticultural Tools and Equipment'},\n",
       "      'Harvesting Equipment': {'name': 'Harvesting Equipment',\n",
       "       'children': {},\n",
       "       'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology > Horticultural Tools and Equipment'}},\n",
       "     'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture > Horticultural Technology'}},\n",
       "   'path': 'All Knowledge > Applied Sciences > Agriculture > Horticulture'}},\n",
       " 'path': 'All Knowledge > Applied Sciences > Agriculture'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fetch Subtopics of a leaf node\n",
    "\n",
    "# subtopics_name = leaf_topic_json['path']\n",
    "leaf_subtopics = atlas.get_topic_hierarchy(leaf_topic_json['path'] + ' > ' + leaf_topic_json['name'])\n",
    "leaf_subtopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the JSON to the folder structure\n",
    "atlas.write_topic_hierarchy(leaf_subtopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json\n"
     ]
    }
   ],
   "source": [
    "!ls 'public/knowledge_atlas/All Knowledge/Technology/Engineering/Mechanical Engineering'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "# openai.organization = \"org-lmbVjLtK0ogCDQASTvLynITa\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.Model.list()\n",
    "\n",
    "models = openai.Model.list()\n",
    "list(map(lambda a : a['id'], models['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNatural Language Processing (NLP) : The field of Artificial Intelligence that deals with analyzing, understanding, and generating natural language.\\n- Text Analysis : The process of extracting and understanding meaningful patterns from text data.\\n- Natural Language Generation : The process of automatically generating natural language from structured data.\\n- Natural Language Understanding : The process of recognizing the meaning of an utterance and deriving an appropriate response.\\n- Text Summarization : The process of condensing a text document into a shorter version that preserves the most important information.\\n- Sentiment Analysis : The process of identifying and classifying opinions expressed in text data.'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLD PROMPT\n",
    "topic = \"Natural Language Processing (NLP)\"\n",
    "result = llm(f'''\n",
    "In broad terms provide a 1 sentence description of \"{topic}\" then provide at the highest level, what are the main topics or subcategories within \"{topic}\"\n",
    "Provie outputs in the following format :\n",
    "- {topic} : <brief description of {topic}>\n",
    "- <topic 1> : <brief description of topic 1>\n",
    "- <topic 2> : <brief description of topic 2>\n",
    "etc\n",
    "''')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsText = result\n",
    "\n",
    "resArr = resultsText.split('\\n')\n",
    "\n",
    "import re\n",
    "arrTopics = []\n",
    "for i in resArr:\n",
    "    if not len(i): continue\n",
    "    topicObj = {\n",
    "        \n",
    "        # get first group from match\n",
    "        \"topic\": re.search(r'^\\-? *([^:]+?) ?:', i).group(1),\n",
    "        \"description\": re.search(r': ?(.+)', i).group(1)\n",
    "    }\n",
    "    arrTopics.append(topicObj)\n",
    "\n",
    "\n",
    "# resultsText\n",
    "# resArr\n",
    "# arrTopics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Natural Language Processing (NLP)',\n",
       " 'description': 'The field of Artificial Intelligence that deals with analyzing, understanding, and generating natural language.',\n",
       " 'subtopics': [{'topic': 'Text Analysis',\n",
       "   'description': 'The process of extracting and understanding meaningful patterns from text data.'},\n",
       "  {'topic': 'Natural Language Generation',\n",
       "   'description': 'The process of automatically generating natural language from structured data.'},\n",
       "  {'topic': 'Natural Language Understanding',\n",
       "   'description': 'The process of recognizing the meaning of an utterance and deriving an appropriate response.'},\n",
       "  {'topic': 'Text Summarization',\n",
       "   'description': 'The process of condensing a text document into a shorter version that preserves the most important information.'},\n",
       "  {'topic': 'Sentiment Analysis',\n",
       "   'description': 'The process of identifying and classifying opinions expressed in text data.'}]}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find original topic\n",
    "topicObj = [i for i in arrTopics if i[\"topic\"] == topic][0]\n",
    "subTopics = [i for i in arrTopics if i[\"topic\"] != topic]\n",
    "topicObj['subtopics'] = subTopics\n",
    "topicObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to json file\n",
    "with open(f'public/knowledge-tree/{topic.lower().replace(\" \", \"-\")}.json', 'w') as outfile:\n",
    "    json.dump([topicObj], outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/amclean/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/amclean/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'h': No scheme supplied. Perhaps you meant http://h?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m map_prompt_template \u001b[39m=\u001b[39m PromptTemplate(template\u001b[39m=\u001b[39mmap_prompt, input_variables\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprospect\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m     12\u001b[0m     \u001b[39m# Set a really small chunk size, just to show.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     chunk_size \u001b[39m=\u001b[39m \u001b[39m800\u001b[39m,\n\u001b[1;32m     14\u001b[0m     chunk_overlap  \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m docs \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_documents(UnstructuredURLLoader(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://en.wikipedia.org/wiki/Artificial_intelligence\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mload())\n\u001b[1;32m     17\u001b[0m \u001b[39m# docs = text_splitter.split_documents(\"Hello, this is a test. Can you hear me?\")\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# docs = [\"Hello, this is a test. Can you hear me?\"]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m chain \u001b[39m=\u001b[39m load_summarize_chain(llm,\n\u001b[1;32m     21\u001b[0m     chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmap_reduce\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     map_prompt\u001b[39m=\u001b[39mmap_prompt_template,\n\u001b[1;32m     23\u001b[0m     \u001b[39m# combine_prompt=combine_prompt_template,\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/document_loaders/url.py:28\u001b[0m, in \u001b[0;36mUnstructuredURLLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m docs: List[Document] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[1;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murls:\n\u001b[0;32m---> 28\u001b[0m     elements \u001b[39m=\u001b[39m partition_html(url\u001b[39m=\u001b[39;49murl)\n\u001b[1;32m     29\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(el) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m elements])\n\u001b[1;32m     30\u001b[0m     metadata \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: url}\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/unstructured/partition/html.py:70\u001b[0m, in \u001b[0;36mpartition_html\u001b[0;34m(filename, file, text, url, encoding, include_page_breaks, include_metadata, parser)\u001b[0m\n\u001b[1;32m     67\u001b[0m     document \u001b[39m=\u001b[39m HTMLDocument\u001b[39m.\u001b[39mfrom_string(_text, parser\u001b[39m=\u001b[39mparser)\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m url \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m response\u001b[39m.\u001b[39mok:\n\u001b[1;32m     72\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mURL return an error: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/sessions.py:573\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39m# Create the Request.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[1;32m    562\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[1;32m    563\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    571\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 573\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[1;32m    575\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    577\u001b[0m settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    578\u001b[0m     prep\u001b[39m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    579\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[39m=\u001b[39m get_netrc_auth(request\u001b[39m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[1;32m    485\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[1;32m    486\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    487\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[1;32m    488\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m    489\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[1;32m    490\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(\n\u001b[1;32m    491\u001b[0m         request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict\n\u001b[1;32m    492\u001b[0m     ),\n\u001b[1;32m    493\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[1;32m    494\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[1;32m    495\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[1;32m    496\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    498\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 368\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_url(url, params)\n\u001b[1;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39m*\u001b[39me\u001b[39m.\u001b[39margs)\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    440\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No scheme supplied. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPerhaps you meant http://\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m host:\n\u001b[1;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No host supplied\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'h': No scheme supplied. Perhaps you meant http://h?"
     ]
    }
   ],
   "source": [
    "map_prompt = \"\"\"Below is a section of a website about {prospect}\n",
    "\n",
    "Write a concise summary about {prospect}. If the information is not about {prospect}, exclude it from your summary.\n",
    "\n",
    "{text}\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\", \"prospect\"])\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 0\n",
    ")\n",
    "docs = text_splitter.split_documents(UnstructuredURLLoader(\"https://en.wikipedia.org/wiki/Artificial_intelligence\").load())\n",
    "# docs = text_splitter.split_documents(\"Hello, this is a test. Can you hear me?\")\n",
    "# docs = [\"Hello, this is a test. Can you hear me?\"]\n",
    "\n",
    "chain = load_summarize_chain(llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt_template,\n",
    "    # combine_prompt=combine_prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m chain({\u001b[39m\"\u001b[39;49m\u001b[39minput_documents\u001b[39;49m\u001b[39m\"\u001b[39;49m: docs, \u001b[39m# The seven docs that were created before\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcompany\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mRapidRoad\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39msales_rep\u001b[39;49m\u001b[39m\"\u001b[39;49m : \u001b[39m\"\u001b[39;49m\u001b[39mGreg\u001b[39;49m\u001b[39m\"\u001b[39;49m, \\\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mprospect\u001b[39;49m\u001b[39m\"\u001b[39;49m : \u001b[39m\"\u001b[39;49m\u001b[39mGitLab\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m })\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chains/base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chains/base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    109\u001b[0m     inputs,\n\u001b[1;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:56\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m     55\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m---> 56\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys)\n\u001b[1;32m     57\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chains/combine_documents/map_reduce.py:141\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcombine_docs\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m, docs: List[Document], token_max: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m3000\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    133\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[39m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mapply(\n\u001b[1;32m    140\u001b[0m         \u001b[39m# FYI - this is parallelized and so it is fast.\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m         [{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_variable_name: d\u001b[39m.\u001b[39mpage_content}, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs} \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_results(results, docs, token_max, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/langchain/chains/combine_documents/map_reduce.py:141\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcombine_docs\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m, docs: List[Document], token_max: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m3000\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    133\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[39m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mapply(\n\u001b[1;32m    140\u001b[0m         \u001b[39m# FYI - this is parallelized and so it is fast.\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m         [{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_variable_name: d\u001b[39m.\u001b[39;49mpage_content}, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs} \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_results(results, docs, token_max, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "output = chain({\"input_documents\": docs, # The seven docs that were created before\n",
    "    \"company\": \"RapidRoad\",\n",
    "    \"sales_rep\" : \"Greg\", \\\n",
    "    \"prospect\" : \"GitLab\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/gxt0xjxs5m544crvyy8tc2qw0000gp/T/ipykernel_44507/2395516112.py:1: RuntimeWarning: coroutine 'BaseLLM.agenerate' was never awaited\n",
      "  res = llm.agenerate(\"This is a test\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m res \u001b[39m=\u001b[39m llm\u001b[39m.\u001b[39magenerate(\u001b[39m\"\u001b[39m\u001b[39mThis is a test\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m chain \u001b[39m=\u001b[39m load_summarize_chain(llm, \u001b[39m\"\u001b[39m\u001b[39mmap_reduce\u001b[39m\u001b[39m\"\u001b[39m, map_prompt \u001b[39m=\u001b[39m PromptTemplate(\u001b[39m\"\u001b[39;49m\u001b[39mThis is a test\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      5\u001b[0m loader \u001b[39m=\u001b[39m UnstructuredURLLoader(\u001b[39m\"\u001b[39m\u001b[39mhttps://www.nytimes.com/2020/06/23/us/politics/trump-russia-bounties.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m doc \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pydantic/main.py:332\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "res = llm.agenerate(\"This is a test\")\n",
    "\n",
    "chain = load_summarize_chain(llm, \"map_reduce\", map_prompt = PromptTemplate(\"This is a test\"))\n",
    "\n",
    "loader = UnstructuredURLLoader(\"https://www.nytimes.com/2020/06/23/us/politics/trump-russia-bounties.html\")\n",
    "\n",
    "doc = loader.load()\n",
    "\n",
    "# print(doc)\n",
    "# output results ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
